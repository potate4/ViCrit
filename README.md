<div align="center">

<h1>ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs</h1>

<p align="center">
  <a href="https://huggingface.co/datasets/russwang/ViCrit-Bench">ðŸ¤—ViCrit-Bench</a> â€¢ <a href="https://huggingface.co/datasets/russwang/ThinkLite-VL-70k">ðŸ“ŠViCrit Training Dataset</a>â€¢ <a href="https://arxiv.org/abs/2504.07934">ðŸ“„Paper</a>
</p>

</div>

Official codebase of "ViCrit: A Verifiable Reinforcement Learning Proxy Task for Visual Perception in VLMs". We will release all codes in one week.

If you found this work useful, consider giving this repository a star and citing our paper as followed:
```
@article{wang2025sota,
  title={SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement},
  author={Wang, Xiyao and Yang, Zhengyuan and Feng, Chao and Lu, Hongjin and Li, Linjie and Lin, Chung-Ching and Lin, Kevin and Huang, Furong and Wang, Lijuan},
  journal={arXiv preprint arXiv:2504.07934},
  year={2025}
}
```
